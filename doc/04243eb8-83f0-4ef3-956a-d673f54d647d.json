{
    "summary": "The code imports libraries, defines functions for URL formatting and webpage data fetching using XPath. It handles exceptions during requests and retrieves information from websites to store in \"data.json\".",
    "details": [
        {
            "comment": "This code imports various libraries and defines three functions. The \"format_url\" function formats a URL with query parameters, the \"get_url\" function generates a Baidu search URL based on a keyword, and the \"get_page\" function sends an HTTP GET request to the generated URL using specified headers and encodes the response as UTF-8.",
            "location": "\"/media/root/Prima/works/generated_docs/lazer_doc/src/multilingual/rockstar/the-real-wheel.py\":0-39",
            "content": "import requests\nimport urllib.parse\nfrom requests.exceptions import RequestException\nfrom urllib.parse import urljoin\nfrom lxml import etree\nimport re\nimport json\n# \u767e\u5ea6\u641c\u7d22\u63a5\u53e3\ndef format_url(url, params: dict=None) -> str:\n    query_str = urllib.parse.urlencode(params)\n    return f'{ url }?{ query_str }'\ndef get_url(keyword):\n    params = {\n        'wd': str(keyword)\n    }\n    url = \"https://www.baidu.com/s\"\n    url = format_url(url, params)\n    # print(url)\n    return url\ndef get_page(url):\n    try:\n        headers = {\n            'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36',\n            'accept-language': 'zh-CN,zh;q=0.9',\n            'cache-control': 'max-age=0',\n            'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8'\n        }\n        response = requests.get(url=url,headers=headers)\n        # \u66f4\u6539\u7f16\u7801\u65b9\u5f0f\uff0c\u5426\u5219\u4f1a\u51fa\u73b0\u4e71\u7801\u7684\u60c5\u51b5\n        response.encoding = \"utf-8\"\n        print(response.status_code)"
        },
        {
            "comment": "The code is a function that parses the content of a website's pages. It fetches HTML from a URL, extracts specific data elements (title, sub-url, and abstract) using XPath, and handles exceptions during requests. The function is called for each page number passed to the `parse_page` function.",
            "location": "\"/media/root/Prima/works/generated_docs/lazer_doc/src/multilingual/rockstar/the-real-wheel.py\":40-73",
            "content": "        # print(response.text)\n        if response.status_code == 200:\n            return response.text\n        return None\n    except RequestException:\n        return None\ndef parse_page(url,page):\n    for i in range(1,int(page)+1):\n        print(\"\u6b63\u5728\u722c\u53d6\u7b2c{}\u9875....\".format(i))\n        title = \"\"\n        sub_url = \"\"\n        abstract = \"\"\n        flag = 11\n        if i == 1:\n            flag = 10\n        html = get_page(url)\n        content = etree.HTML(html)\n        for j in range(1,flag):\n            data = {}\n            res_title = content.xpath('//*[@id=\"%d\"]/h3/a' % ((i - 1) * 10 + j))\n            if res_title:\n                title = res_title[0].xpath('string(.)')\n            sub_url = content.xpath('//*[@id=\"%d\"]/h3/a/@href' % ((i - 1) * 10 + j))\n            if sub_url:\n                sub_url = sub_url[0]\n            res_abstract = content.xpath('//*[@id=\"%d\"]/div[@class=\"c-abstract\"]'%((i-1)*10+j))\n            if res_abstract:\n                abstract = res_abstract[0].xpath('string(.)')\n            else:\n  "
        },
        {
            "comment": "This code is part of a web scraper that retrieves information from a website. It takes a keyword and page number as input, then fetches the corresponding page using the `get_url` function. The `parse_page` function extracts data such as title, sub-URL, abstract, and other information from the page. If more pages exist, it continues to fetch and parse them. The scraped data is stored in a dictionary called `data`, and written to a file named \"data.json\". If there are no more pages, it prints \"\u65e0\u66f4\u591a\u9875\u9762\uff01\uff5e\" and returns.",
            "location": "\"/media/root/Prima/works/generated_docs/lazer_doc/src/multilingual/rockstar/the-real-wheel.py\":73-100",
            "content": "              res_abstract = content.xpath('//*[@id=\"%d\"]/div/div[2]/div[@class=\"c-abstract\"]'%((i-1)*10+j))\n                if res_abstract:\n                    abstract = res_abstract[0].xpath('string(.)')\n                    # res_abstract = content.xpath('//*[@id=\"%d\"]/div/div[2]/p[1]'%((i-1)*10+j))\n            # if not abstract:\n            #     abstract = content.xpath('//*[@id=\"%d\"]/div/div[2]/p[1]'%((i-1)*10+j))[0].xpath('string(.)')\n            data['title'] = title\n            data['sub_url'] = sub_url\n            data['abstract'] = abstract\n            rel_url = content.xpath('//*[@id=\"page\"]/a[{}]/@href'.format(flag))\n            if rel_url:\n                url = urljoin(url, rel_url[0])\n            else:\n                print(\"\u65e0\u66f4\u591a\u9875\u9762\uff01\uff5e\")\n                return\n            yield data\ndef main():\n    keyword = input(\"\u8f93\u5165\u5173\u952e\u5b57:\")\n    page = input(\"\u8f93\u5165\u67e5\u627e\u9875\u6570:\")\n    url = get_url(keyword)\n    results = parse_page(url,page)\n    # \u5199\u5165\u6587\u4ef6\n    file = open(\"data.json\", 'w+', encoding='utf-8')\n    for result in results:"
        },
        {
            "comment": "This code prints the \"result\" variable and writes it to a file in JSON format with indentation and non-ASCII characters preserved. The code is executed only if the script is run directly, not imported as a module.",
            "location": "\"/media/root/Prima/works/generated_docs/lazer_doc/src/multilingual/rockstar/the-real-wheel.py\":101-105",
            "content": "        print(result)\n        file.write(json.dumps(result, indent=2, ensure_ascii=False))\nif __name__ == '__main__':\n    main()"
        }
    ]
}